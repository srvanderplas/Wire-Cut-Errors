---
title: "Multiple Comparisons in Toolmark Evidence"
author: "Susan Vanderplas, Heike Hofmann"
format: pdf
---

```{r setup, include = F}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```

## Introduction

-   Problems with database searches and multiple comparisons in forensics
-   Fingerprint - madrid bombing
-   DNA databases
-   Firearms and toolmarks?? NIBIN/IBIS issues, but more broadly there are issues

One of the common suggestions in the 2016 PCAST report across pattern disciplines in forensic science was the importance of creating huge databases of e.g. known prints and firearms to support research into matches and closest non-matches[@pcast, fingerprints pg 11, 88, firearms pg 12]. As researchers, we concur with this suggestion, as it is critical for developing objective algorithms and creating useful black-box studies. We have spent considerable time assembling large data sets of tool marks, bullets, and cartridge cases to support our research as well as create public resources to accelerate future research [@csafeDataPortal]. However, we are wary about the implications of database searches across forensic disciplines, for reasons also mentioned in the PCAST report: the necessity of understanding the random match probability for searches against these databases, in particular when using degraded evidence often found in crime scenes[@pcast, pg 52].

This issue has been raised in the past with regard to DNA [@thompson2003] and fingerprints [@fine2006]; one of the many issues identified in the aftermath of the 2004 Madrid bombing case was that the IAFIS database used to locate similar prints is extremely large and thus it is possible for the database to locate unusually similar non-matches. This issue will almost certainly become an issue in other pattern disciplines as databases of firearms evidence such as NIBIN @nibin2021 become more commonly utilized by law enforcement. In this paper, however, we examine a more subtle issue present in tool mark examinations: searches within evidence collected as part of a single case. We begin with a hypothetical set of three scenarios involving the collection of tool mark evidence and then assess the statistical issues involved with each scenario and explore possible resolutions to those issues.

### Examination Process

Let us consider the process of toolmark examination - an examiner is given a tool recovered from a suspect as well as a wire recovered from the scene. The examiner will typically take the tool and use it to cut a piece of metal, known as a blade cut, in order to record the markings of the entire cutting surface simultaneously. This process may be repeated at multiple angles in order to record the effect of different contact surfaces on the resulting striations. The resulting blade cut will be compared to the wire using either visual inspection or perhaps in the future a numerical comparison algorithm similar to those developed for bullet striations [@hare2017automatic] and cartridge cases [@zemmels2023].

The examiner will compare blade cuts from all cutting surfaces during this process. Tools used for wire cuts typically have either 2 or 4 cutting surfaces. Examiners may make multiple cuts at multiple angles; this will increase the number of available blade cuts for comparison.

For simplicity, let us for now assume that only a single cut under one controlled angle was made.

### Counting Comparisons

Let us consider a single blade cut from a single cutting surface. Define the blade cut to be of length $\ell$ and the wire to have diameter $d$; we will also assume that the wire is fully covered with striations suitable for comparison.

At minimum, there must be $\ell/d$ comparisons in order to assess whether the tool matches the wire; in this case, the comparisons are essentially independent of each other (conditional on the striation patterns) because no overlapping data is used. Of course, in this situation, we are overlooking the potential for partial matches and assuming that everything is lined up perfectly to produce this minimum number of comparisons; in practice, of course, the number of comparisons in this situation would likely be much higher.

At a maximum, both the blade and the wire are either digitally scanned at the same resolution of $r$ mm, or visually examined using a microscope with a digital view of a certain resolution which can be translated into an equivalent resolution to the digital scan. In this case, there may be as many as $\ell/r- d/r + 1$ comparisons performed in order to find the optimal alignment between the two samples[^1]. Of course, these comparisons are highly dependent, as each sequential comparison shares much of the same data with the previous and next comparisons. While it is likely possible to model this autocorrelation and compute an effective number of comparisons accounting for the autocorrelation, developing this model is outside the scope of this paper.

[^1]: This assumes we restrict the wire to be completely contained within the bounds of the blade surface. If we allow for partial matches and restrict these matches to require at least $k$ points of overlap, then this becomes $\ell/r - d/r + k + 1$.

Thus, we will consider the two extremes: $\ell/d$ completely independent comparisons and $\ell/r - d/r + 1$ dependent comparisons. The true number of visual or numerical comparisons lies somewhere between these two values.

To make this more concrete, consider the pair of pliers shown in @fig-wire-cutter, which has a 1.5 cm cutting surface machined on both sides to produce a peaked cross-section. When used to cut a wire, the wire rests against a rectangular surface used to hold it in place; the blade is pushed into the wire, producing striae resulting from imperfections in side A on one half of the wire and striae from imperfections and wear in side B on the other.

![Wire cutter with 1.5 cm cutting surface beveled on both sides](../fig/wire_cutter.png){#fig-wire-cutter}

```{r}
resolution <- 0.645 # res in mum
length_blade <- 15 # length in mm
wire_diam <- 2 # diameter in mm
mm_to_mum <- 1000 # conversion

obs_blade <- round(length_blade * mm_to_mum/resolution)
obs_wire <- round(wire_diam * mm_to_mum/resolution)
alg_compare <- obs_blade - obs_wire + 1

examiner_increment <- 0.2 # increment in mm
examiner_compare <- (length_blade - wire_diam)/examiner_increment + 1
```

A scan of a cut made by the blade at $`r resolution`\mu m$ resolution will produce approximately $`r length_blade` \times `r mm_to_mum`/`r resolution` = `r format(obs_blade, big.mark = ',')`$ observations; a scan of a 2mm wire would produce $`r wire_diam` \times `r mm_to_mum`/`r resolution` = `r format(obs_wire, big.mark = ',')`$ observations, and computationally aligning these two data sequences using maximum cross-correlation would require $`r obs_blade` - `r obs_wire` + 1 = `r format(alg_compare, big.mark = ',')`$ (obviously dependent) comparisons. Under an optical microscope, an examiner might move the wire at 0.2mm increments along the blade cut surface for a total of $`r length_blade`/`r examiner_increment` - `r wire_diam`/`r examiner_increment` + 1 = `r format(examiner_compare, big.mark = ',')`$ distinct comparisons. Then, we must consider that the examiner or algorithm must compare the wire to both side A and side B; we then double the number of total comparisons made to $`r format(alg_compare*2, big.mark = ',')`$ and $`r examiner_compare*2`$ for the algorithm and the examiner, respectively.

### Comparison counts

When assessing the total number of comparisons, we will consider two extremes: first, a set of completely independent comparisons made by dividing the blade cut up into a series of non-overlapping segments the same size as the wire. XXX add picture XXX The second extreme is a series of comparisons made by sliding the wire along the blade cut in increments equal to the resolution of the scan or optical viewer (depending on whether this comparison is done automatically or visually). Of course, the reality is that an algorithm or examiner will likely make a number of comparisons between these two extremes, however, rather than consider all possible comparison numbers within this span, it is more efficient to explore what happens at each endpoint first.

## Thought Experiment

```{r shop-data}
library(tibble)
library(dplyr)
library(tidyr)
library(purrr)

cutting_surfaces <- tribble(
  ~type, ~length, ~surfaces, ~tools,
  "Pliers", 1.5, 2, 10,
  "Pliers", 1, 4, 3,
  "Side cutters", 1, 4, 1,
  "Side cutters", 2, 4, 2,
  "Scissors", 8, 2, 14,
  "Tin snips", 4, 2, 4,
  "Lineman pliers", 2, 4, 2,
  "Lineman pliers", 1, 4, 1,
  "Wire strippers", 1, 2, 2,
  "Long handled cutting pliers", 2, 4, 1,
  "Long handled cutting pliers", 3, 4, 1,
  "Utility knife blades", 6.2, 2, 50
) %>%
  mutate(total_cutting_length = length*surfaces*tools)

total_cutting_surface = sum(cutting_surfaces$total_cutting_length)

dad_surfaces <- tribble(
  ~type, ~length, ~surfaces, ~tools,
  "Pliers", 1.8, 2, 1,
  "Pliers", 1.6, 2, 1,
  "Pliers", 1.1, 2, 1,
  "Wire cutters", 2, 2, 1,
  "Wire cutters", 1.5, 2, 1,
  "Wire cutters", 1, 2, 2,
  "Other cutters", 8, 2, 1,
  "Other cutters", 4, 4, 1,
  "Scissors", 7.5, 2, 5,
  "Utility knife blades", 6.2, 2, 160,
  "Razor blades", 4, 2, 14,
  "Knife", 4, 2, 1,
  "Knife", 2, 2, 1,
  "Clippers", 4, 2, 1
) %>%
  mutate(total_cutting_length = length*surfaces*tools)

dad_total_cutting_surface = sum(dad_surfaces$total_cutting_length)
```

Consider, for example a situation where someone builds a bomb, and a wire fragment is recovered from un-detonated explosive. We will examine how the forensic examination might proceed in three different cases:

1.  Examiners identify a suspect and locate a single tool which is believed to have been used to construct the bomb. Examiners would like to determine whether this tool is a forensic match to wires within the undetonated bomb.

2.  Examiners identify a suspect and locate a garage full of tools, one of which may have been used to construct the bomb. Examiners would like to identify which tool(s) were used to cut the wires during bomb construction.

3.  Examiners identify several suspect, each of whom has a set of tools, and wish to determine which suspect(s) may have constructed the bomb based off of the toolmark comparisons.

We will consider wires ranging in diameter from 2mm (solid 12 gauge wire) to 0.0116 mm (stranded 12 gauge wire may be composed of 49 strands of 0.0116 mm diameter wire) for the purposes of this thought experiment; these values represent types of wire easily obtainable at a local hardware store.

<!-- https://www.calmont.com/wp-content/uploads/calmont-eng-wire-gauge.pdf -->

<!-- https://en.wikipedia.org/wiki/American_wire_gauge -->

### Single Tool, Single Cut Comparisons

Let us first consider the situation where a single tool is recovered from the suspect's house that is viewed as likely to have made the wire cut. Ultimately, in order to compare tool marks in this scenario, the examiner or algorithm completes the equivalent to a database search resulting from a single piece of evidence. The dangers of such searches are well known and have been cited in forensic missteps such as the Madrid bombing case, as discussed in @li2023; @newman2007; @mayfield2006report [Pg 137].

While $`r examiner_compare*2`$ visual comparisons might not seem so terrible, this is the simplest of the 3 scenarios we consider; each scenario presents a progressively more complex problem.

### A Garage of Comparisons

In our next scenario, investigators identify a suspect and collect all of the tools in the suspect's residence which might have been used to construct the bomb.

Let us consider the garage of one of the authors of this paper; @fig-shop-layout shows the garage work bench and tool storage in typical condition. While there is no reason to think the author's garage is representative of all garages, the general setup and number of tools in the garage is not unusual for a suburban household where residents may dabble in automotive repair, home improvement, or woodworking.

::: {#fig-shop-layout layout-ncol="2"}
![Shop Bench Tool rack](../fig/PXL_20231110_190517827.jpg)

![Shop Side Tool rack](../fig/PXL_20231110_190522765.jpg)

Layout of tool storage in the author's garage. For this study, we considered only tools which might reasonably be used to cut wires.
:::

```{r}
#| label: tbl-shop-surfaces
#| tbl-cap: "Shop cutting surfaces. All lengths in cm."
#| echo: false
#| message: false
knitr::kable(cutting_surfaces %>% rename(Type = type, `Length (cm)` = length, `Cutting Surfaces` = surfaces, `# Tools` = tools, `Total Cutting Length (cm)` = total_cutting_length))
```

```{r}
#| label: tbl-shop-comparisons
#| tbl-cap: "Comparions performed by tool type, assuming digital scans at a resolution of $0.625\\mu m$ and visual comparisons performed at $0.2 mm$ intervals along the test blade impression."
#| echo: false
#| message: false
comparisons <- cutting_surfaces %>%
  mutate(digital = (length*10*mm_to_mum/resolution - wire_diam*mm_to_mum/resolution + 1)*surfaces*tools,
         analog = (length*10/examiner_increment - wire_diam/examiner_increment + 1)) %>%
  group_by(type) %>%
  summarize(digital = sum(round(digital)), analog = sum(round(analog))) %>%
  rename(`Tool type` = type, Algorithm = digital, Examiner = analog)
  
compare_tbl <- bind_rows(comparisons, tibble(`Tool type` = "Total", Algorithm = sum(comparisons$Algorithm), Examiner = sum(comparisons$Examiner)))
knitr::kable(compare_tbl, format.args = list(big.mark=','))
```

We assembled the easily available tools from the house and garage which might reasonably be used to cut wires[^2], including pliers, wire cutters and strippers, scissors, tongs, and utility knives. Estimated cutting surface length and quantity of each type of tool is provided in @tbl-shop-surfaces. The total length of all cutting surfaces of relevant tools in the author's garage is `r total_cutting_surface` cm; primary contributions to the total length are the 50 pack of utility knife blades and the 14 pairs of full-size scissors which could be located throughout the house. Of course, a thorough search of the garage and house, as one would expect from professionals investigating an actual crime, would yield far more cutting surfaces to compare against.

[^2]: Reasonably is defined as we (the authors) have used a tool like this to cut wires while doing home improvement projects in the past.

As in Scenario 1, the wire fragment recovered from the un-detonated explosive would be compared to blade surface test impressions generated from each cutting surface in the garage. However, unlike in Scenario 1, we have `r format(total_cutting_surface, big.mark=',')` cm of cutting surfaces to work with. We can apply our comparison formula on a by-surface basis to yield the digital and analog comparison estimates shown in @tbl-shop-comparisons. Overall, our algorithm would make `r format(sum(comparisons$Algorithm), big.mark=',')` (dependent) comparisons and an examiner doing a visual inspection would make `r format(sum(comparisons$Examiner), big.mark=',')` comparisons under the assumptions we made in Scenario 1.

### Multiple Suspects

To fully understand the magnitude of this problem, suppose that we have a group of 4 additional individuals who may have contributed to building the un-detonated bomb. These individuals are each associated with the author and have hobbies that include building electronic devices, home improvement, welding, and woodworking (thus, they each have sets of tools). As part of the investigation, each individuals' tools are confiscated and examined; blade cuts are made of each cutting surface to be matched to the wire in evidence. @tbl-garage-comparisons shows the number of comparisons which would need to be performed to ensure that all wire-cutting tools in each suspect's garage are compared to the evidence from the scene.

```{r}
#| label: tbl-garage-comparisons
#| tbl-cap: "Total cutting length of easily accessible wire-cutting tools for 4 individuals associated with the author."
#| echo: false
#| message: false
set.seed(42309427)


n_tools <- c(40, 20, 30)
n_blades <- sample(5:75, size = 3)

tool_options <- select(bind_rows(cutting_surfaces, dad_surfaces), 1:3) %>% unique()

blades <- filter(tool_options, type %in% c("Utility knife blades", "Razor blades"))

other_tools <- filter(tool_options, !type %in% c("Utility knife blades", "Razor blades"))

dad_tools <- dad_surfaces %>% 
  mutate(suspect = 4) %>% select(-total_cutting_length)

our_tools <- cutting_surfaces %>% mutate(suspect = 0) %>% select(-total_cutting_length)

sim_garages <- tibble(suspect = 1:3, n_tools = n_tools, n_blades = n_blades) %>%
  mutate(data = map2(
    n_tools, n_blades, 
    ~bind_rows(
      slice_sample(other_tools, n = .x, replace = T), 
      slice_sample(blades, n = .y, replace = T)) 
  )) %>%
  unnest(data) %>%
  group_by(suspect, type, length, surfaces) %>% 
  summarize(tools = n()) %>%
  ungroup()

garages <- bind_rows(sim_garages, dad_tools, our_tools) %>%
  group_by(suspect) %>%
   mutate(digital = (length*10*mm_to_mum/resolution - wire_diam*mm_to_mum/resolution + 1)*surfaces*tools,
         analog = (length*10/examiner_increment - wire_diam/examiner_increment + 1)*surfaces*tools) 

garage_sum <- garages %>%
  summarize(
    total_cutting_length = sum(length * surfaces * tools), 
    digital = sum(digital), 
    analog = sum(analog)) %>%
  mutate(suspect = as.character(suspect))

garage_sum_tot <- bind_rows(garage_sum, tibble(suspect = "Total", total_cutting_length = sum(garage_sum$total_cutting_length), digital = sum(garage_sum$digital), analog = sum(garage_sum$analog)))

garage_sum_tot %>%
  rename(Individual = suspect, `Total Cutting Length (cm)` = total_cutting_length, "Algorithm" = digital, "Examiner" = analog) %>%
  knitr::kable(format.args = list(big.mark = ','))
```

If investigators were to attempt to determine which of the suspected individuals cut the wire in evidence, they would need to do `r format(sum(garage_sum$analog), big.mark = ',')` distinct visual comparisons. Even if there is an incredibly small false positive error rate, the odds of a false identification are much more likely in this scenario than either of the previous two scenarios. But how likely? In the next section, we describe two different scenarios for calculating the overall likelihood of a false identification using simple probability calculations and estimated coincidental match probabilities as well as a theoretical approach designed to mimic the approach used with database searches that return the $N$ most similar results.

## The Problems with Database Searches

### Random Match Probability

### Score-based Distributions

## Potential Solutions

We need to have an explicit relationship between random match probability and amount of signal (assessed by length, number of features, overall striae depth, etc.). Until we have this kind of relationship, it will be hard to use error rates (even if they were known for toolmarks) from algorithms or black-box studies in practical situations.

We need much more study of real data, examiner evaluations, and performance of algorithms in situations which mimic real casework. We also need to quantify the strength, distinctiveness, and total number of striations to ensure that comparisons are being made only in situations where random matches are unlikely to occur.
